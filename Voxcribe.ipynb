{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMw1KYIgjLjGHUP3b1HHe+P"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "CeKtt1H7CqUo",
        "outputId": "c7bcd1a2-1e1b-4c81-b2c8-936b4087f300",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-23a7d91dd5d4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mazure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcognitiveservices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeech\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspeechsdk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import json\n",
        "import trace\n",
        "from typing import final\n",
        "import uuid\n",
        "import requests\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "import zipfile\n",
        "import base64\n",
        "import threading\n",
        "import urllib3\n",
        "import ssl\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ssl._create_default_https_context = ssl._create_stdlib_context\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
      ],
      "metadata": {
        "id": "y9LslOy_JsUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Azure Speech API credentials from environment variables"
      ],
      "metadata": {
        "id": "eKhlqaHPJ9Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subscription_key = \"\" #insert key\n",
        "region = \"eastus2\"\n",
        "api_url = \"https://api.openai.com/v1/chat/completions\"\n",
        "tts_url = \"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts\"\n",
        "AUDIO_FOLDER = '.\\\\Audio'\n",
        "ZIP_FOLDER = '.\\\\Audio'"
      ],
      "metadata": {
        "id": "6p6C4-6VJ7xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_trace_id():\n",
        "  return str(uuid.uuid4())"
      ],
      "metadata": {
        "id": "_zOsnRFbNeS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TTS"
      ],
      "metadata": {
        "id": "hVPo_49_No0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_voice_options(url):\n",
        "  table = pd.read_html(url)\n",
        "  voice_dict = defaultdict(list)\n",
        "\n",
        "  for table in tables:\n",
        "    table.columns = [str(col).strip() for col in table.columns]\n",
        "\n",
        "    if \"Language\" in table.columns and \"Text to speech voices\" in table.columns:\n",
        "      language_col = \"Language\"\n",
        "      voice_col = \"Text to speech voices\"\n",
        "\n",
        "      df = table[[language_col, voice_col]].dropna()\n",
        "\n",
        "      for _, row in df.iterrows():\n",
        "        lang = row[language_col].strip()\n",
        "        soup = BeautifulSoup(str(row[\"Text to speech voices\"]), \"html.parser\")\n",
        "\n",
        "        list_items = soup.select(\"l1\")\n",
        "        vocies = [l1.get_text(strip=True) for l1 in list_items]\n",
        "\n",
        "        if not voices:\n",
        "          raw_text = soup.get_text(seperator=\"\\n\")\n",
        "          voices = [v.strip() for v in raw_text.split(\")\") if v.strip()]\n",
        "\n",
        "        for voice in voices:\n",
        "          voice = voice.replace(\"(Female\",\"(Female)\").replace(\"(Male\", \"(Male)\")\n",
        "\n",
        "      return voice_dict\n",
        "\n",
        "  st.error(\"Failed to fetch voice options from the URL.\")\n",
        "  return {}"
      ],
      "metadata": {
        "id": "MphnWaShNphZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_tts():\n",
        "  for key in ['zip_file_ready', 'zip_file_path', 'transcription_file_ready', 'transcription_file_path', 'enable_transcription', 'selected_voices', 'trace_id']:\n",
        "    if key not in session_state:\n",
        "      st.session_state[key] = None\n",
        "  st.markdown(\"\"\"\n",
        "  <h1 style='font-size: 2.5rem; margin-bottom: 0.5 rem;>\n",
        "    Voxcribe\n",
        "  </h1>\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "  st.markdown(\"<div style='margin-top: 20px;'></div>\", unsafe_allow_html=True)\n",
        "\n",
        "  st.markdown(\"\"\"<h3 style='color:#2ecc71;'>Render Multiple Phrases</h3>\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "  uploaded_file = st.file_uploader(\"Upload a CSV file\", key=\"file_uploader\", type=[\"csv\"])\n",
        "\n",
        "  file_url = 'Audio_Render_Template.csv'\n",
        "  with open(file_url, \"rb\") as file:\n",
        "      csv_file_data = file.read()\n",
        "      encoded_csv = base64.b64encode(csv_file_data).decode(\"utf-8\")\n",
        "      data_url = f\"data:text/csv;base64,{encoded_csv}\"\n",
        "\n",
        "  if uploaded_file is not None:\n",
        "    st.success(\"CSV uploaded successfully! Click ‘Generate Audio & Transcription’ to process.\")\n",
        "    st.button(\"Generate Audio & Transcription\", key=\"generate_audio_button\", on_click=on_generate_audio_click, args=(uploaded_file,))\n",
        "\n",
        "  st.markdown(\"\"\"\n",
        "  <div style=\"display: flex; align-items: center; text-align: center; margin:15px 0;\">\n",
        "    <hr style=\"flex:1; border: none; border-top: 1px solid grey;\" />\n",
        "    <span style=\"padding: 10px; color: lightgrey; font-weight: bold;\">OR</span>\n",
        "    <hr style=\"flex:1; border: none; border-top: 1px solid grey;\" />\n",
        "  </div>\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "  st.markdown(\"\"\"<h3 style='color:#2ecc71;'>Render Single Phrase</h3>\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "  input_text = st.text_area(\"Enter text here:\", height=108)\n",
        "  voice_dict = fetch_voice_options(tts_url)\n",
        "\n",
        "  selected_language = st.multiselect(\"Choose a Language\", list(voice_dict.keys()))\n",
        "  selected_voices = {}\n",
        "\n",
        "  for lang in selected_language:\n",
        "    voices = voice_dict[lang]\n",
        "    selected = st.multiselect(f\"Choose Talent for {lang}\", options=voices, key=f\"voices_for_{lang}\")\n",
        "\n",
        "  enable_transcription = st.checkbox(\"Generate Transcription\")\n",
        "\n",
        "  if 'single_audio_done' not in st.session_state:\n",
        "    st.session_state['single_audio_done'] = False\n",
        "\n",
        "  if 'single_audio_path' not in st.session_state:\n",
        "    st.session_state['single_audio_path'] = \"\"\n",
        "\n",
        "  if 'single_transcription_path' not in st.session_state:\n",
        "    st.session_state['single_transcription_path'] = \"\"\n",
        "\n",
        "  if st.button(\"Render Single Phrase\"):\n",
        "    if input_text.strip() == \"\":\n",
        "        st.warning(\"Enter text\")\n",
        "    elif not selected_voices:\n",
        "        st.warning(\"Please select at least one talent\")\n",
        "    else:\n",
        "        trace_id = str(uuid.uuid4())[:0]\n",
        "        output_path = os.path.join(\"single_outputs\", f\"render_{trace_id}\")\n",
        "        os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "        file_name = f\"text_{trace_id}\"\n",
        "        text_to_send = input_text\n",
        "\n",
        "        transcription_row = {\n",
        "            \"File Name\": file_name,\n",
        "            \"Text\": text_to_send\n",
        "            }\n",
        "\n",
        "        for lang, selected_voice_list in selected_voices.items():\n",
        "          for voice in selected_voice_list:\n",
        "            language_code = voice.replace(\"(Female\", \"\").replace(\"(Male)\", \"\").strip()\n",
        "            language_directory = os.path.join(output_path, lang)\n",
        "            os.makedirs(language_directory, exist_ok=True)\n",
        "\n",
        "            audio_filename = os.path.join(language_directory, f\"{file_name}_{language_code}.wav\")\n",
        "\n",
        "            if language_code.strip().startswith(\"en\"):\n",
        "              api_response, trace_id = text_to_send\n",
        "            else:\n",
        "              api_response, trace_id = call_custom_api(api_url, text_to_send, lang, trace_id)\n",
        "\n",
        "            transcription_row[lang] = api_response\n",
        "            st.write(lang, language_code)\n",
        "\n",
        "            success = generate_audio(api_response, audio_filename, lang, language_code)\n",
        "\n",
        "            if not success:\n",
        "              st.error(f\"Failed to generate for {file_name}\")\n",
        "\n",
        "        # Create ZIP\n",
        "        zip_filename = os.path.join(\"single_outputs\", f\"{trace_id}_audio.zip\")\n",
        "        with zipfile.ZipFile(zip_filename, \"w\") as zipf:\n",
        "          for root, _, files in os.walk(output_path):\n",
        "            for file in files:\n",
        "              file_path = os.path.join(root, file)\n",
        "              arcname = os.path.relpath(file_path, output_path)\n",
        "              zipf.write(file_path, arcname)\n",
        "\n",
        "        st.session_state['zip_file_ready'] = True\n",
        "        st.session_state['zip_file_path'] = zip_filename\n",
        "\n",
        "        st.session_state['enable_transcription'] = enable_transcription\n",
        "        if enable_transcription:\n",
        "          # Save transcription to CSV\n",
        "          transcription_df = pd.DataFrame([transcription_row])\n",
        "          transcription_filename = os.path.join(output_path, \"transcription.csv\")\n",
        "          transcription_df.to_csv(transcription_filename, index=False, encoding='utf-8-sig')\n",
        "          st.session_state['transcription_file_ready'] = True\n",
        "          st.session_state['transcription_file_path'] = transcription_filename\n",
        "        else:\n",
        "          st.session_state['transcription_file_ready'] = False\n",
        "          st.session_state['transcription_file_path'] = None\n",
        "\n",
        "  # Download Buttons\n",
        "  if st.session_state.get('zip_file_ready') and st.session_state.get('zip_file_path'):\n",
        "    with open(st.session_state['zip_file_path'], \"rb\") as f:\n",
        "      st.download_button(\"Download Audio ZIP\", f, file_name=os.path.basename(st.session_state['zip_file_path']))\n",
        "\n",
        "  if st.session_state.get('transcription_file_ready') and st.session_state.get('enable_transcription'):\n",
        "    with open(st.session_state['transcription_file_path'], \"rb\") as f:\n",
        "      st.download_button(\"Download Transcribed CSV\", f, file_name=\"transcription.csv\", mime=\"text/csv\")\n",
        "\n",
        "  # Sidebar Instructions\n",
        "  st.sidebar.markdown(\"Instructions:\")\n",
        "  st.sidebar.markdown(f\"\"\"\n",
        "  - To Render Multiple Phrases:\n",
        "    * Click [here]({data_url}) to download the template CSV file.\n",
        "    * You can add/delete the 'Language #' columns in the sheet.\n",
        "    * Upload CSV file using ‘Browse files’.\n",
        "    * Click ‘Generate Audio & Transcription’.\n",
        "    * Once processed, a ZIP file will be available to download.\n",
        "    * Refer [here](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts) for language/talent support.\n",
        "  \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "  st.sidebar.markdown(f\"\"\"\n",
        "  - To Render Single Phrase:\n",
        "    * Enter the phrase.\n",
        "    * Choose language(s) and associated talent(s).\n",
        "    * To get transcription, check ‘Generate Transcription’.\n",
        "    * Click \"Render Single Phrase\".\n",
        "    * A ZIP file will be generated for audio(s), and optionally transcription CSV.\n",
        "  \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "  # Multi Phrase Rendering\n",
        "  def on_generate_audio_click(uploaded_file):\n",
        "    voice_dict = fetch_voice_options(tts_url)\n",
        "    voice_to_language = {}\n",
        "    for language, voices in voice_dict.items():\n",
        "      for voice in voices:\n",
        "          clean_voice = voice.replace(\"(Female)\",\"\").replace(\"(Male)\",\"\").strip()\n",
        "          voice_to_language[clean_voice] = language\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "      trace_id = generate_trace_id()\n",
        "      output_folder = os.path.join(AUDIO_FOLDER, trace_id)\n",
        "      os.makedirs(output_folder, exist_ok=True)\n",
        "      df = pd.read_csv(uploaded_file)\n",
        "\n",
        "      # The below code will extract all the distict languages and create a folder\n",
        "      language_columns = [col for col in df.columns if 'Language' in col]\n",
        "      # Combine all language columns into a single Series\n",
        "      if language_columns:\n",
        "        all_languages = pd.concat([df[col] for col in language_columns])\n",
        "        # Get distint language names\n",
        "        distinct_languages = all_languages.unique()\n",
        "      else:\n",
        "        distinct_languages = []\n",
        "\n",
        "      transcription_rows = []\n",
        "\n",
        "      for index, row in df.iterrows():\n",
        "        file_name = row['File Name']\n",
        "        text_to_send = row['Text']\n",
        "        transcription_row = {\n",
        "          \"File Name\": file_name,\n",
        "          \"Text\": text_to_send\n",
        "          }\n",
        "\n",
        "        for col in df.columns:\n",
        "          language = str(row[col]).replace(\"(Female)\", \"\").replace(\"(Male)\", \"\").strip()\n",
        "          language_name = voice_to_language.get(language, language)\n",
        "\n",
        "          if language != 'nan':\n",
        "              language_code = str(language.split(\"-\")[0])\n",
        "\n",
        "              language_directory = os.path.join(output_folder, language)\n",
        "              os.makedirs(language_directory, exist_ok=True)\n",
        "\n",
        "              audio_filename = os.path.join(language_directory, f\"{file_name}.wav\")\n",
        "\n",
        "              if language_code.strip().startswith(\"en\"):\n",
        "                api_response = text_to_send\n",
        "              else:\n",
        "                api_response, trace_id = call_custom_api(api_url, text_to_send, language, trace_id)\n",
        "\n",
        "              if language_name in transcription_row:\n",
        "                language_name = f\"{language_name} ({language})\"\n",
        "\n",
        "              transcription_row[language_name] = api_response\n",
        "\n",
        "              success = generate_audio(api_response, audio_filename, language_name, language)\n",
        "\n",
        "              if not success:\n",
        "                st.error(f\"Failed to generate audio for {file_name}\")\n",
        "\n",
        "        transcription_rows.append(transcription_row)\n",
        "\n",
        "      transcription_df = pd.DataFrame(transcription_rows)\n",
        "      transcription_filename = os.path.join(output_folder, \"transcription.csv\")\n",
        "      transcription_df.to_csv(transcription_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "      zip_filename = create_zip(trace_id, output_folder)\n",
        "\n",
        "      if zip_filename:\n",
        "        st.download_button(\n",
        "          label=\"Download ZIP File\",\n",
        "          data=open(zip_filename, \"rb\"),\n",
        "          file_name=os.path.basename(zip_filename),\n",
        "          key=\"download_zip_button\"\n",
        "        )\n",
        "\n",
        "        st.success(\"Audio generated successfully!\")"
      ],
      "metadata": {
        "id": "Ulvb_4bUP3_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate audio\n",
        "def generate_audio(api_response, audio_filename, language, language_code):\n",
        "    data_context = api_response\n",
        "    try:\n",
        "        # print(data_context)\n",
        "\n",
        "        # Configure speech synthesis\n",
        "        speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=region)\n",
        "        speech_config.speech_synthesis_language = language\n",
        "        speech_config.speech_synthesis_voice_name = language_code\n",
        "        speech_config.set_speech_synthesis_output_format(\n",
        "            speechsdk.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw\n",
        "        )\n",
        "\n",
        "        # Configure audio output (file)\n",
        "        audio_config = speechsdk.audio.AudioOutputConfig(filename=audio_filename)\n",
        "\n",
        "        # Create synthesizer and generate speech\n",
        "        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
        "\n",
        "        # Syntesize Speech\n",
        "        result = synthesizer.speak_text(data_context)\n",
        "        audio_data = result.audio_data\n",
        "\n",
        "        with open(audio_filename, \"wb\") as audio_file:\n",
        "          audio_file.write(audio_data)\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error generating audio:\", e)\n",
        "        return False"
      ],
      "metadata": {
        "id": "OTFd3ZsLTRI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_custom_api(api_url, text, language, trace_id):\n",
        "  headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"cache-control\": \"no-cache\"\n",
        "    }\n",
        "\n",
        "  data = {\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a professional translator.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Translate this to {language} literally, word-for-word. Do not add extra words, adapt meanings, or change the structure beyond direct translation of each term. Preserve the exact formatting and placeholders as they appear in the original text:\\n\\n{text}\"}\n",
        "        ],\n",
        "        \"temperature\": 0.1,\n",
        "        \"maxTokens\": 500,\n",
        "        \"choiceCount\": 1,\n",
        "        \"frequencyPenalty\": 0,\n",
        "        \"presencePenalty\": 0,\n",
        "    }\n",
        "\n",
        "  response = requests.post(api_url, headers=headers, json=data)\n",
        "  response.raise_for_status()  # raise an error for bad status codes\n",
        "\n",
        "  content_value = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "  return content_value, trace_id"
      ],
      "metadata": {
        "id": "qZBoUnwJaQLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_zip(trace_id, output_folder):\n",
        "  zip_filename = os.path.join(ZIP_FOLDER, f\"{trace_id}_audio.zip\")\n",
        "\n",
        "  try:\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    # Iterate through files in output folder and add them to the zip\n",
        "      for root, _, files in os.walk(output_folder):\n",
        "        for file in files:\n",
        "          file_path = os.path.join(root, file)\n",
        "          arcname = os.path.relpath(file_path, output_folder)\n",
        "          zipf.write(file_path, arcname)\n",
        "\n",
        "    return zip_filename\n",
        "\n",
        "  except Exception as e:\n",
        "    st.error(f\"Failed to create ZIP file: {e}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "vkjDYHuKcfwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STT"
      ],
      "metadata": {
        "id": "OR8MINF8fKdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "language_code_map = {\n",
        "    \"English\": \"en-US\",\n",
        "    \"Spanish\": \"es-ES\",\n",
        "    \"French\": \"fr-FR\",\n",
        "    \"German\": \"de-DE\",\n",
        "    \"Chinese\": \"zh-CN\",\n",
        "    \"Japanese\": \"ja-JP\",\n",
        "    \"Korean\": \"ko-KR\",\n",
        "    \"Hindi\": \"hi-IN\",\n",
        "    \"Arabic\": \"ar-SA\",\n",
        "    \"Russian\": \"ru-RU, ru-UA\",\n",
        "    \"Portuguese\": \"pt-BR\",\n",
        "    \"Italian\": \"it-IT\",\n",
        "    \"Dutch\": \"nl-NL\",\n",
        "    \"Swedish\": \"sv-SE\",\n",
        "    \"Norwegian\": \"no-NO\",\n",
        "    \"Finnish\": \"fi-FI\",\n",
        "    \"Danish\": \"da-DK\",\n",
        "    \"Greek\": \"el-GR\",\n",
        "    \"Turkish\": \"tr-TR\",\n",
        "    \"Indonesian\": \"id-ID\",\n",
        "    \"Thai\": \"th-TH\",\n",
        "    \"Vietnamese:\": \"vi-VN, vi-LA\",\n",
        "    \"Malay\": \"ms-MY\",\n",
        "    \"Filipino\": \"fil-PH\",\n",
        "    \"Tagalog\": \"tl-PH\",\n",
        "    \"Romanian\": \"ro-RO\",\n",
        "    \"Ukrainian\": \"uk-UA\",\n",
        "    \"Czech\": \"cs-CZ\",\n",
        "    \"Hungarian\": \"hu-HU\",\n",
        "    \"Polish\": \"pl-PL\",\n",
        "    \"Romanian\": \"ro-RO\",\n",
        "    \"Slovenian\": \"sl-SI\",\n",
        "    \"Bosnian\": \"bs-BA\",\n",
        "    \"Croatian\": \"hr-HR\",\n",
        "    \"Serbian\": \"sr-RS\",\n",
        "    \"Albanian\": \"sq-AL\"}"
      ],
      "metadata": {
        "id": "nXLcFe0tfJze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe audio\n",
        "def transcribe_audio(filepath, lang=None):\n",
        "    speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=region)\n",
        "\n",
        "    if lang:\n",
        "        speech_config.speech_recognition_language = lang\n",
        "\n",
        "    audio_input = speechsdk.AudioConfig(filename=filepath)\n",
        "    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_input)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    def handle_final_result(evt):\n",
        "        if evt.result.text:\n",
        "            all_results.append(evt.result.text)\n",
        "\n",
        "    recognizer.recognized.connect(handle_final_result)\n",
        "    recognizer.start_continuous_recognition()\n",
        "\n",
        "    done = threading.Event()\n",
        "\n",
        "    def stop_cb(evt):\n",
        "        done.set()\n",
        "\n",
        "    recognizer.session_stopped.connect(stop_cb)\n",
        "    recognizer.canceled.connect(stop_cb)\n",
        "\n",
        "    done.wait()\n",
        "    recognizer.stop_continuous_recognition()\n",
        "\n",
        "    return \" \".join(all_results)\n",
        "\n",
        "# Translate text\n",
        "def translate_text(text, targets, trace_id):\n",
        "    translations = []\n",
        "    for tgt_lang in targets:\n",
        "        translated, _ = call_custom_api(api_url, text, tgt_lang, trace_id)\n",
        "        translations.append(translated)\n",
        "    return translations\n",
        "\n",
        "# Detect language\n",
        "def detect_language(text, trace_id):\n",
        "    prompt = \"Identify the language this text is written in and respond with only one word (e.g., English, Spanish).\"\n",
        "    try:\n",
        "        response, _ = call_custom_api(api_url, prompt, \"English\", trace_id)\n",
        "        return response.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Language detection failed: {e}\")\n",
        "        return \"unknown\"\n",
        "\n",
        "def write_csv(lang_data, output_dir, enable_translation, translate_targets):\n",
        "  results = {}\n",
        "\n",
        "  for lang, rows in lang_data.items():\n",
        "    headers = [\"File Name\", lang]\n",
        "    if enable_translation:\n",
        "        headers += translate_targets\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=headers)\n",
        "    csv_path = os.path.join(output_dir, f\"{lang}.csv\")\n",
        "    df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
        "    results[lang] = csv_path\n",
        "\n",
        "  return results\n",
        "\n",
        "def process_audio_files(input_paths, autodetect, enable_translation, translate_targets, trace_id):\n",
        "    base_dir = \"stt_temp\"\n",
        "    os.makedirs(base_dir, exist_ok=True)\n",
        "    output_dir = os.path.join(base_dir, f\"csv_output_{trace_id}\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    lang_data = {}\n",
        "\n",
        "    for path in input_paths:\n",
        "        if os.path.isdir(path):\n",
        "            language_name = os.path.basename(path)\n",
        "            lang_code = language_code_map.get(language_name.lower())\n",
        "            files = [f for f in os.listdir(path) if f.endswith(\".wav\")]\n",
        "\n",
        "            for f in files:\n",
        "                audio_path = os.path.join(path, f)\n",
        "                text = transcribe_audio(audio_path, lang=None if autodetect else lang_code)\n",
        "                row = [f, text]\n",
        "                if enable_translation:\n",
        "                    row += translate_text(text, translate_targets, trace_id)\n",
        "                lang_data.setdefault(language_name, []).append(row)\n",
        "\n",
        "        elif os.path.isfile(path) and path.endswith(\".wav\"):\n",
        "            filename = os.path.basename(path)\n",
        "            text = transcribe_audio(path, lang=None if autodetect else None)\n",
        "            detected_lang = detect_language(text, trace_id) if autodetect else \"Unknown\"\n",
        "            row = [filename, text]\n",
        "\n",
        "            if enable_translation:\n",
        "                row += translate_text(text, translate_targets, trace_id)\n",
        "            lang_data.setdefault(detected_lang, []).append(row)\n",
        "\n",
        "    results = write_csv(lang_data, output_dir, enable_translation, translate_targets)\n",
        "    return results\n",
        "\n",
        "def display_stt():\n",
        "    st.markdown(\"\"\"\n",
        "    <h1 style='font-size: 2.5rem; margin-bottom: 0.55rem;'>\n",
        "    Voxcribe\n",
        "    </h1>\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"<div style='margin-top: 20px;'></div>\", unsafe_allow_html=True)\n",
        "\n",
        "    uploaded_zip = st.file_uploader(\"Upload a ZIP file containing audio folders or files\", type=[\"zip\"])\n",
        "\n",
        "    auto_detect = st.checkbox(\"Auto Detect Language\")\n",
        "    enable_translation = st.checkbox(\"Translate\")\n",
        "\n",
        "    translate_targets = []\n",
        "    if enable_translation:\n",
        "        translate_targets = st.multiselect(\"Translate To:\", [\n",
        "          \"English\", \"Spanish\",\"French\",\"German\",\"Chinese\",\"Japanese\",\"Korean\",\"Hindi\",\"Arabic\",\"Russian\",\"Portuguese\",\"Italian\",\"Dutch\",\n",
        "          \"Swedish\",\"Norwegian\",\"Finnish\",\"Danish\",\"Greek\",\"Turkish\",\"Indonesian\",\"Thai\",\"Vietnamese:\",\"Malay\",\"Filipino\",\"Tagalog\",\"Romanian\",\n",
        "          \"Ukrainian\",\"Czech\",\"Hungarian\",\"Polish\",\"Romanian\",\"Slovenian\",\"Bosnian\",\"Croatian\",\"Serbian\",\"Albanian\"\n",
        "        ])\n",
        "\n",
        "    if uploaded_zip and st.button(\"Transcribe Audio\"):\n",
        "        with st.spinner(\"Expecto Patronum...\"):\n",
        "            trace_id = str(uuid.uuid4())[:8]\n",
        "            working_dir = os.path.join(\"stt_temp\", trace_id)\n",
        "            os.makedirs(working_dir, exist_ok=True)\n",
        "\n",
        "            # Save and unzip uploaded file\n",
        "            zip_path = os.path.join(working_dir, \"input.zip\")\n",
        "            with open(zip_path, \"wb\") as f:\n",
        "                f.write(uploaded_zip.read())\n",
        "\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(working_dir)\n",
        "\n",
        "            # Analyze folder structure\n",
        "            folder_contents = os.listdir(working_dir)\n",
        "            input_paths = [os.path.join(working_dir, name) for name in folder_contents if name != \"input.zip\"]\n",
        "            structured = all(os.path.isdir(p) for p in input_paths)\n",
        "\n",
        "            if not structured and not auto_detect:\n",
        "              st.error(\"Unstructured audio files detected. Please enable Auto Detect Language.\")\n",
        "              return\n",
        "\n",
        "            # Process\n",
        "            transcription_results = process_audio_files(input_paths, auto_detect, enable_translation, translate_targets, trace_id)\n",
        "\n",
        "            # ZIP CSVs\n",
        "            output_zip_path = os.path.join(\"stt_temp\", f\"{trace_id}_output.zip\")\n",
        "            with zipfile.ZipFile(output_zip_path, 'w') as zipf:\n",
        "                for lang, csv_path in transcription_results.values():\n",
        "                  arcname = f\"{lang}.csv\"\n",
        "                  zipf.write(csv_path, arcname)\n",
        "\n",
        "            # Show Download\n",
        "            with open(output_zip_path, \"rb\") as f:\n",
        "              st.download_button(\"Download Transcription\", data=f, file_name=\"transcriptions.zip\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  tab1, tab2 = st.tabs([\"Text to Speech (TTS)\", \"Speech to Text (STT)\"])\n",
        "  with tab1:\n",
        "    display_tts()\n",
        "  with tab2:\n",
        "    display_stt()"
      ],
      "metadata": {
        "id": "RiBxTumFdNNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "te8Z-VOue1bo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}